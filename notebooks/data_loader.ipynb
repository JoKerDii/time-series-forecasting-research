{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea24e494",
   "metadata": {},
   "source": [
    "# Walmart Sales Dataset \n",
    "\n",
    "## Overview\n",
    "\n",
    "This dataset contains historical sales data for 45 Walmart stores across different regions, designed for predicting department-wide sales. The dataset spans from February 5, 2010, to November 1, 2012, and includes various external factors that may influence sales performance. (Data Source: https://www.kaggle.com/competitions/walmart-recruiting-store-sales-forecasting/data)\n",
    "\n",
    "A key challenge in this dataset is modeling the effects of promotional markdowns on holiday weeks, where evaluation metrics are weighted five times higher than non-holiday weeks for the four major holidays: Super Bowl, Labor Day, Thanksgiving, and Christmas.\n",
    "\n",
    "## Dataset Files\n",
    "\n",
    "### 1. train.csv\n",
    "**Purpose**: Historical training data for model development  \n",
    "**Date Range**: February 5, 2010 to November 1, 2012  \n",
    "**Key Fields**:\n",
    "- `Store`: Store identifier (1-45)\n",
    "- `Dept`: Department number within each store\n",
    "- `Date`: Week ending date\n",
    "- `Weekly_Sales`: Target variable - sales for the given department and store\n",
    "- `IsHoliday`: Boolean indicator for special holiday weeks\n",
    "\n",
    "### 2. test.csv\n",
    "**Purpose**: Test dataset for predictions (identical structure to train.csv, excluding Weekly_Sales)  \n",
    "**Usage**: Contains store-department-date combinations requiring sales predictions\n",
    "\n",
    "### 3. stores.csv\n",
    "**Purpose**: Store metadata and characteristics  \n",
    "**Key Fields**:\n",
    "- Store type classification\n",
    "- Store size information\n",
    "- Anonymized store attributes\n",
    "\n",
    "### 4. features.csv\n",
    "**Purpose**: External factors and promotional data  \n",
    "**Key Fields**:\n",
    "- `Store`: Store identifier\n",
    "- `Date`: Week ending date\n",
    "- `Temperature`: Regional average temperature\n",
    "- `Fuel_Price`: Regional fuel costs\n",
    "- `MarkDown1-5`: Promotional markdown data (available after November 2011, with gaps)\n",
    "- `CPI`: Consumer Price Index\n",
    "- `Unemployment`: Regional unemployment rate\n",
    "- `IsHoliday`: Holiday week indicator\n",
    "\n",
    "## Data Characteristics\n",
    "\n",
    "### Holiday Weighting\n",
    "Special evaluation weighting (5x) applies to weeks containing:\n",
    "- **Super Bowl**: 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13\n",
    "- **Labor Day**: 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13\n",
    "- **Thanksgiving**: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13\n",
    "- **Christmas**: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13\n",
    "\n",
    "### Data Quality Notes\n",
    "- **Markdown Data**: Only available after November 2011 and not consistently across all stores\n",
    "- **Missing Values**: Markdown fields contain NA values where data is unavailable\n",
    "- **Anonymization**: Store and markdown information is anonymized for privacy\n",
    "\n",
    "## Loading Instructions\n",
    "\n",
    "Use the provided `WalmartDataLoader` class to load and explore the dataset:\n",
    "\n",
    "```python\n",
    "from walmart_data_loader import WalmartDataLoader\n",
    "\n",
    "# Initialize and load data\n",
    "loader = WalmartDataLoader()\n",
    "success = loader.load_data()\n",
    "\n",
    "if success:\n",
    "    # Display dataset overview\n",
    "    loader.basic_info()\n",
    "```\n",
    "\n",
    "### File Structure Requirements\n",
    "Ensure the following files are in your `data/` directory:\n",
    "- `train.csv`\n",
    "- `test.csv` \n",
    "- `stores.csv`\n",
    "- `features.csv`\n",
    "\n",
    "## Modeling Considerations\n",
    "\n",
    "1. **Holiday Impact**: Model the amplified importance of holiday weeks in predictions\n",
    "2. **Missing Markdowns**: Handle sparse promotional data appropriately\n",
    "3. **Regional Factors**: Incorporate temperature, fuel prices, and economic indicators\n",
    "4. **Store Heterogeneity**: Account for different store types and sizes\n",
    "5. **Temporal Patterns**: Consider seasonal and weekly sales patterns\n",
    "\n",
    "## Expected Outcomes\n",
    "\n",
    "The goal is to predict `Weekly_Sales` for each store-department-date combination in the test set, with particular attention to accuracy during weighted holiday periods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a00425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets loaded successfully!\n",
      "================================================================================\n",
      "WALMART SALES FORECASTING - DATASET OVERVIEW\n",
      "================================================================================\n",
      "\n",
      " Training Data:\n",
      "   Shape: (421570, 5)\n",
      "   Columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday']\n",
      "   Memory usage: 13.27 MB\n",
      "   Date range: 2010-02-05 00:00:00 to 2012-10-26 00:00:00\n",
      "   Unique stores: 45\n",
      "   Unique departments: 81\n",
      "   Total sales records: 421,570\n",
      "\n",
      " Test Data:\n",
      "   Shape: (115064, 4)\n",
      "   Columns: ['Store', 'Dept', 'Date', 'IsHoliday']\n",
      "   Memory usage: 2.74 MB\n",
      "\n",
      " Stores Data:\n",
      "   Shape: (45, 3)\n",
      "   Columns: ['Store', 'Type', 'Size']\n",
      "   Memory usage: 0.00 MB\n",
      "\n",
      " Features Data:\n",
      "   Shape: (8190, 12)\n",
      "   Columns: ['Store', 'Date', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'IsHoliday']\n",
      "   Memory usage: 0.70 MB\n",
      "Data loading complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class WalmartDataLoader:\n",
    "    \"\"\"\n",
    "    Data loader for actual Walmart sales dataset from Kaggle\n",
    "    Dataset: Walmart Recruiting - Store Sales Forecasting\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.features_data = None\n",
    "        self.stores_data = None\n",
    "        self.holiday_weights = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load all CSV files\"\"\"\n",
    "        try:\n",
    "            self.train_data = pd.read_csv(\"data/train.csv\")\n",
    "            self.test_data = pd.read_csv(\"data/test.csv\")\n",
    "            self.stores_data = pd.read_csv(\"data/stores.csv\")\n",
    "            self.features_data = pd.read_csv(\"data/features.csv\")\n",
    "\n",
    "            # Convert dates\n",
    "            self.train_data[\"Date\"] = pd.to_datetime(self.train_data[\"Date\"])\n",
    "            self.test_data[\"Date\"] = pd.to_datetime(self.test_data[\"Date\"])\n",
    "            self.features_data[\"Date\"] = pd.to_datetime(self.features_data[\"Date\"])\n",
    "\n",
    "            print(\"All datasets loaded successfully!\")\n",
    "            return True\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error loading files: {e}\")\n",
    "            print(\n",
    "                \"Please make sure all CSV files (train.csv, test.csv, stores.csv, features.csv) are in the working directory.\"\n",
    "            )\n",
    "            return False\n",
    "\n",
    "    def basic_info(self):\n",
    "        \"\"\"Display basic information about all datasets\"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"WALMART SALES FORECASTING - DATASET OVERVIEW\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        datasets = {\n",
    "            \"Training Data\": self.train_data,\n",
    "            \"Test Data\": self.test_data,\n",
    "            \"Stores Data\": self.stores_data,\n",
    "            \"Features Data\": self.features_data,\n",
    "        }\n",
    "\n",
    "        for name, df in datasets.items():\n",
    "            if df is not None:\n",
    "                print(f\"\\n {name}:\")\n",
    "                print(f\"   Shape: {df.shape}\")\n",
    "                print(f\"   Columns: {list(df.columns)}\")\n",
    "                print(\n",
    "                    f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\"\n",
    "                )\n",
    "\n",
    "                if name == \"Training Data\":\n",
    "                    print(f\"   Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "                    print(f\"   Unique stores: {df['Store'].nunique()}\")\n",
    "                    print(f\"   Unique departments: {df['Dept'].nunique()}\")\n",
    "                    print(f\"   Total sales records: {len(df):,}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loader = WalmartDataLoader()\n",
    "    loader.load_data()\n",
    "    loader.basic_info()\n",
    "\n",
    "    print(\"Data loading complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "banking_ts_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
